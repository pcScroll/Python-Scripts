
import arcpy
import os
import time
import multiprocessing
from tqdm import tqdm  # Install with `pip install tqdm`

# Set parameters
sde_path = r"C:\path\to\your_connection.sde"  # Update with your SDE connection file path
output_gdb = r"C:\path\to\output.gdb"  # Update with your desired output File GDB path
log_file = r"C:\path\to\export_log.txt"  # Log file to track errors

# Create File Geodatabase if not exists
if not arcpy.Exists(output_gdb):
    arcpy.CreateFileGDB_management(os.path.dirname(output_gdb), os.path.basename(output_gdb))
    print(f"Created File GDB: {output_gdb}")

# Get all feature classes and tables in SDE
arcpy.env.workspace = sde_path
datasets = arcpy.ListFeatureClasses() + arcpy.ListTables()

# Track progress
total = len(datasets)
if total == 0:
    print("No data found in the SDE.")
    exit()

# Function to export a dataset
def export_dataset(dataset):
    output_path = os.path.join(output_gdb, os.path.basename(dataset))
    start_time = time.time()
    
    try:
        arcpy.Copy_management(dataset, output_path)
        duration = round(time.time() - start_time, 2)
        return (dataset, "Success", duration)
    except Exception as e:
        with open(log_file, "a") as log:
            log.write(f"Failed to export {dataset}: {str(e)}\n")
        return (dataset, "Failed", 0)

# Run exports in parallel using multiprocessing
if __name__ == "__main__":
    print(f"Starting parallel export of {total} datasets...\n")
    
    # Use 4 parallel processes (adjust based on your system)
    pool = multiprocessing.Pool(processes=4)

    # Process with progress bar
    results = list(tqdm(pool.imap(export_dataset, datasets), total=total))

    # Close the multiprocessing pool
    pool.close()
    pool.join()

    # Summary
    success_count = sum(1 for _, status, _ in results if status == "Success")
    failed_count = total - success_count
    print(f"\nExport completed! ✅ {success_count} succeeded, ❌ {failed_count} failed.")
    if failed_count > 0:
        print(f"Check the log file for errors: {log_file}")
========================================================



import arcpy
import os

# Set SDE Connection
sde_path = r"C:\path\to\your_connection.sde"  # Update with your SDE connection file path
arcpy.env.workspace = sde_path

# Efficiently list feature classes by checking datasets first
datasets = arcpy.ListDatasets(feature_type="Feature") or [""]

# Collect all feature classes
feature_classes = []
for dataset in datasets:
    feature_classes.extend(arcpy.ListFeatureClasses(feature_dataset=dataset))

# Collect tables
tables = arcpy.ListTables()

# Merge lists
datasets = feature_classes + tables

print(f"Found {len(feature_classes)} feature classes and {len(tables)} tables.")
======================================================================================

import arcpy
import os
import time

def export_sde_to_gdb(sde_connection, output_gdb):
    try:
        # Set environments
        arcpy.env.overwriteOutput = True
        arcpy.env.workspace = sde_connection

        # Create output GDB if it doesn't exist
        if not arcpy.Exists(output_gdb):
            arcpy.management.CreateFileGDB(
                out_folder_path=os.path.dirname(output_gdb),
                out_name=os.path.basename(output_gdb)
            )
            print(f"Created File GDB: {output_gdb}")

        # List datasets
        fcs = arcpy.ListFeatureClasses()
        tables = arcpy.ListTables()

        # Track total datasets
        total_datasets = len(fcs) + len(tables)
        print(f"Total datasets to export: {total_datasets}")

        # Export feature classes
        if fcs:
            print(f"\nExporting {len(fcs)} feature classes...")
            start_time = time.time()
            for i, fc in enumerate(fcs, 1):
                arcpy.conversion.FeatureClassToGeodatabase(
                    Input_Features=fc,
                    Output_Geodatabase=output_gdb
                )
                print(f"Exported feature class {i}/{len(fcs)}: {fc}")
            print(f"Feature classes exported in {time.time() - start_time:.2f} seconds.")

        # Export tables
        if tables:
            print(f"\nExporting {len(tables)} tables...")
            start_time = time.time()
            for i, table in enumerate(tables, 1):
                arcpy.conversion.TableToGeodatabase(
                    Input_Data=table,
                    Output_Geodatabase=output_gdb
                )
                print(f"Exported table {i}/{len(tables)}: {table}")
            print(f"Tables exported in {time.time() - start_time:.2f} seconds.")

        print("\nExport completed successfully!")

    except arcpy.ExecuteError as e:
        print(f"ArcPy Error: {e}")
    except Exception as e:
        print(f"Error: {e}")

# Example usage
if __name__ == "__main__":
    sde_path = r"C:\Path\To\Your\Connection.sde"
    output_gdb = r"C:\Output\Data.gdb"
    export_sde_to_gdb(sde_path, output_gdb)



=======================================================================

import arcpy
import os
import time

def export_sde_to_gdb(sde_connection, output_gdb):
    try:
        # Set environments
        arcpy.env.overwriteOutput = True
        arcpy.env.workspace = sde_connection

        # Create output GDB if it doesn't exist
        if not arcpy.Exists(output_gdb):
            arcpy.management.CreateFileGDB(
                out_folder_path=os.path.dirname(output_gdb),
                out_name=os.path.basename(output_gdb)
            )
            print(f"Created File GDB: {output_gdb}")

        # List datasets
        fcs = arcpy.ListFeatureClasses()
        tables = arcpy.ListTables()

        # Track total datasets
        total_datasets = len(fcs) + len(tables)
        print(f"Total datasets to export: {total_datasets}")

        # Export feature classes
        if fcs:
            print(f"\nExporting {len(fcs)} feature classes...")
            start_time = time.time()
            for i, fc in enumerate(fcs, 1):
                # Run the tool and capture the result object
                result = arcpy.conversion.FeatureClassToGeodatabase(
                    Input_Features=fc,
                    Output_Geodatabase=output_gdb
                )
                # Get and print messages
                messages = result.getMessages()
                print(f"Exported feature class {i}/{len(fcs)}: {fc}")
                print(f"Messages: {messages}")
            print(f"Feature classes exported in {time.time() - start_time:.2f} seconds.")

        # Export tables
        if tables:
            print(f"\nExporting {len(tables)} tables...")
            start_time = time.time()
            for i, table in enumerate(tables, 1):
                # Run the tool and capture the result object
                result = arcpy.conversion.TableToGeodatabase(
                    Input_Data=table,
                    Output_Geodatabase=output_gdb
                )
                # Get and print messages
                messages = result.getMessages()
                print(f"Exported table {i}/{len(tables)}: {table}")
                print(f"Messages: {messages}")
            print(f"Tables exported in {time.time() - start_time:.2f} seconds.")

        print("\nExport completed successfully!")

    except arcpy.ExecuteError as e:
        print(f"ArcPy Error: {e}")
    except Exception as e:
        print(f"Error: {e}")

# Example usage
if __name__ == "__main__":
    sde_path = r"C:\Path\To\Your\Connection.sde"
    output_gdb = r"C:\Output\Data.gdb"
    export_sde_to_gdb(sde_path, output_gdb)
===========================================

import arcpy
import os
import time
import logging

def setup_logging(log_file):
    """Set up logging to write to a file."""
    logging.basicConfig(
        filename=log_file,
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    logging.info("Logging initialized.")

def export_sde_to_gdb(sde_connection, output_gdb, log_file):
    try:
        # Set up logging
        setup_logging(log_file)
        logging.info(f"Exporting from SDE: {sde_connection} to File GDB: {output_gdb}")

        # Set environments
        arcpy.env.overwriteOutput = True
        arcpy.env.workspace = sde_connection

        # Create output GDB if it doesn't exist
        if not arcpy.Exists(output_gdb):
            arcpy.management.CreateFileGDB(
                out_folder_path=os.path.dirname(output_gdb),
                out_name=os.path.basename(output_gdb)
            )
            logging.info(f"Created File GDB: {output_gdb}")

        # List datasets
        fcs = arcpy.ListFeatureClasses()
        tables = arcpy.ListTables()

        # Track total datasets
        total_datasets = len(fcs) + len(tables)
        logging.info(f"Total datasets to export: {total_datasets}")

        # Export feature classes
        if fcs:
            logging.info(f"Exporting {len(fcs)} feature classes...")
            start_time = time.time()
            for i, fc in enumerate(fcs, 1):
                try:
                    # Run the tool and capture the result object
                    result = arcpy.conversion.FeatureClassToGeodatabase(
                        Input_Features=fc,
                        Output_Geodatabase=output_gdb
                    )
                    # Log progress and messages
                    logging.info(f"Exported feature class {i}/{len(fcs)}: {fc}")
                    logging.info(f"Messages: {result.getMessages()}")
                except arcpy.ExecuteError as e:
                    logging.error(f"Failed to export feature class {fc}: {e}")
            logging.info(f"Feature classes exported in {time.time() - start_time:.2f} seconds.")

        # Export tables
        if tables:
            logging.info(f"Exporting {len(tables)} tables...")
            start_time = time.time()
            for i, table in enumerate(tables, 1):
                try:
                    # Run the tool and capture the result object
                    result = arcpy.conversion.TableToGeodatabase(
                        Input_Data=table,
                        Output_Geodatabase=output_gdb
                    )
                    # Log progress and messages
                    logging.info(f"Exported table {i}/{len(tables)}: {table}")
                    logging.info(f"Messages: {result.getMessages()}")
                except arcpy.ExecuteError as e:
                    logging.error(f"Failed to export table {table}: {e}")
            logging.info(f"Tables exported in {time.time() - start_time:.2f} seconds.")

        logging.info("Export completed successfully!")

    except Exception as e:
        logging.error(f"Unexpected error: {e}")

# Example usage
if __name__ == "__main__":
    sde_path = r"C:\Path\To\Your\Connection.sde"
    output_gdb = r"C:\Output\Data.gdb"
    log_file = r"C:\Output\export_log.txt"  # Path to the log file
    export_sde_to_gdb(sde_path, output_gdb, log_file)


====================================================================

import arcpy
import os
import time
import logging

def setup_logging(log_file):
    """Set up logging to write to a file."""
    logging.basicConfig(
        filename=log_file,
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    logging.info("Logging initialized.")

def export_sde_to_gdb(sde_connection, output_gdb, log_file):
    try:
        # Set up logging
        setup_logging(log_file)
        logging.info(f"Exporting from SDE: {sde_connection} to File GDB: {output_gdb}")

        # Set environments
        arcpy.env.overwriteOutput = True  # Allow overwriting existing datasets
        arcpy.env.workspace = sde_connection

        # Create output GDB if it doesn't exist
        if not arcpy.Exists(output_gdb):
            arcpy.management.CreateFileGDB(
                out_folder_path=os.path.dirname(output_gdb),
                out_name=os.path.basename(output_gdb)
            )
            logging.info(f"Created File GDB: {output_gdb}")

        # List datasets
        fcs = arcpy.ListFeatureClasses()
        tables = arcpy.ListTables()

        # Track total datasets
        total_datasets = len(fcs) + len(tables)
        logging.info(f"Total datasets to export: {total_datasets}")

        # Export feature classes
        if fcs:
            logging.info(f"Exporting {len(fcs)} feature classes...")
            start_time = time.time()
            for i, fc in enumerate(fcs, 1):
                try:
                    # Check if the dataset exists in the output GDB
                    output_fc = os.path.join(output_gdb, os.path.basename(fc))
                    if arcpy.Exists(output_fc):
                        logging.warning(f"Dataset already exists: {output_fc}. Overwriting...")

                    # Run the tool and capture the result object
                    result = arcpy.conversion.FeatureClassToGeodatabase(
                        Input_Features=fc,
                        Output_Geodatabase=output_gdb
                    )
                    # Log progress and messages
                    logging.info(f"Exported feature class {i}/{len(fcs)}: {fc}")
                    logging.info(f"Messages: {result.getMessages()}")
                except arcpy.ExecuteError as e:
                    if "160246" in str(e):  # Handle Error 160246
                        logging.error(f"Dataset already exists and cannot be overwritten: {fc}. Error: {e}")
                    else:
                        logging.error(f"Failed to export feature class {fc}: {e}")
            logging.info(f"Feature classes exported in {time.time() - start_time:.2f} seconds.")

        # Export tables
        if tables:
            logging.info(f"Exporting {len(tables)} tables...")
            start_time = time.time()
            for i, table in enumerate(tables, 1):
                try:
                    # Check if the dataset exists in the output GDB
                    output_table = os.path.join(output_gdb, os.path.basename(table))
                    if arcpy.Exists(output_table):
                        logging.warning(f"Dataset already exists: {output_table}. Overwriting...")

                    # Run the tool and capture the result object
                    result = arcpy.conversion.TableToGeodatabase(
                        Input_Data=table,
                        Output_Geodatabase=output_gdb
                    )
                    # Log progress and messages
                    logging.info(f"Exported table {i}/{len(tables)}: {table}")
                    logging.info(f"Messages: {result.getMessages()}")
                except arcpy.ExecuteError as e:
                    if "160246" in str(e):  # Handle Error 160246
                        logging.error(f"Dataset already exists and cannot be overwritten: {table}. Error: {e}")
                    else:
                        logging.error(f"Failed to export table {table}: {e}")
            logging.info(f"Tables exported in {time.time() - start_time:.2f} seconds.")

        logging.info("Export completed successfully!")

    except Exception as e:
        logging.error(f"Unexpected error: {e}")

# Example usage
if __name__ == "__main__":
    sde_path = r"C:\Path\To\Your\Connection.sde"
    output_gdb = r"C:\Output\Data.gdb"
    log_file = r"C:\Output\export_log.txt"  # Path to the log file
    export_sde_to_gdb(sde_path, output_gdb, log_file)
